from pydantic import BaseModel
from openai import OpenAI
import os
import traceback


"""
Contains various utility functions to test connectivity to azure services
"""


def send_llm_message():
    """
    Sent a simple message to the llm and extract the response
    """
    azure_endpoint = os.environ.get("OPENAI_ENDPOINT", None)
    api_key = os.environ.get("OPENAI_KEY", None)
    llm = OpenAI(
        base_url=f"{azure_endpoint}openai/v1/",
        api_key=api_key,
    )

    class SampleResultFormat(BaseModel):
        some_strings: list[str]

    try:
        response = llm.chat.completions.parse(
            model="gpt-4.1",
            messages=[
                {"role": "system", "content": "Respond with a json list"},
                {"role": "user", "content": "Hello there"},
            ],
            temperature=0.5,
            max_tokens=1000,
            response_format=SampleResultFormat,
        )
        resp: SampleResultFormat = response.choices[0].message.parsed
        return f"Message successfully generated by the llm: '{resp.some_strings}'"
    except Exception as e:
        return "".join(traceback.TracebackException.from_exception(e).format())
