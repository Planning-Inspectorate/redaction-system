parameters:
- name: env
  type: string
  default: test
  values: [dev, test, prod]

- name: perfConcurrency
  type: number
  default: 5
- name: perfTotal
  type: number
  default: 5
- name: perfTimeoutSeconds
  type: number
  default: 7200
- name: perfPollSeconds
  type: number
  default: 2

pr: none
trigger: none

resources:
  repositories:
    - repository: templates
      type: github
      endpoint: Planning-Inspectorate
      name: Planning-Inspectorate/common-pipeline-templates
      ref: refs/tags/release/3.24.2

extends:
  template: stages/wrapper_ci.yml@templates
  parameters:
    validateName: Redaction Perf
    globalVariables:
      - template: pipelines/azure-pipelines-variables.yml@self

    validationJobs:
      - name: RunPerfTests
        steps:
          - checkout: self
            clean: true
          - checkout: templates

          # ---- Azure auth per env ----
          - ${{ if eq(parameters.env, 'dev') }}:
              - template: ../steps/azure_auth.yml@templates
                parameters:
                  subscriptionId: $(SUBSCRIPTION_ID_DEV)

          - ${{ if eq(parameters.env, 'test') }}:
              - template: ../steps/azure_auth.yml@templates
                parameters:
                  subscriptionId: $(SUBSCRIPTION_ID_TEST)

          - ${{ if eq(parameters.env, 'prod') }}:
              - template: ../steps/azure_auth.yml@templates
                parameters:
                  subscriptionId: $(SUBSCRIPTION_ID_PROD)

          - script: |
              set -e
              cd redaction-system
              python3 -m pip install -r redactor/requirements.txt
            displayName: Install requirements

          # ---- Env wiring per environment (clean + explicit) ----

          - script: |
              set -e
              cd redaction-system/redactor
              export PYTHONPATH="$(pwd)"

              envName="${{ parameters.env }}"

              case "$envName" in
                dev)
                  export E2E_FUNCTION_BASE_URL="$(E2E_FUNCTION_BASE_URL_DEV)"
                  export E2E_CONTAINER_NAME="$(E2E_CONTAINER_NAME_DEV)"
                  export E2E_STORAGE_ACCOUNT="pinsstredactiondevuks"
                  ;;
                test)
                  export E2E_FUNCTION_BASE_URL="$(E2E_FUNCTION_BASE_URL_TEST)"
                  export E2E_CONTAINER_NAME="$(E2E_CONTAINER_NAME_TEST)"
                  export E2E_STORAGE_ACCOUNT="pinsstredactiontestuks"
                  ;;
                prod)
                  export E2E_FUNCTION_BASE_URL="$(E2E_FUNCTION_BASE_URL_PROD)"
                  export E2E_CONTAINER_NAME="$(E2E_CONTAINER_NAME_PROD)"
                  export E2E_STORAGE_ACCOUNT="pinsstredactionproduks"
                  ;;
                *)
                  echo "Unknown env: $envName"
                  exit 1
                  ;;
              esac

              export E2E_RUN_ID="ado-perf-$(Build.BuildId)"

              export PERF_CONCURRENCY="${{ parameters.perfConcurrency }}"
              export PERF_TOTAL="${{ parameters.perfTotal }}"
              export PERF_TIMEOUT_S="${{ parameters.perfTimeoutSeconds }}"
              export PERF_POLL_S="${{ parameters.perfPollSeconds }}"

              echo "env=$envName"
              echo "E2E_FUNCTION_BASE_URL=${E2E_FUNCTION_BASE_URL}"
              echo "E2E_STORAGE_ACCOUNT=${E2E_STORAGE_ACCOUNT}"
              echo "E2E_CONTAINER_NAME=${E2E_CONTAINER_NAME}"
              echo "PERF_CONCURRENCY=${PERF_CONCURRENCY} PERF_TOTAL=${PERF_TOTAL}"

              python3 -m pytest -q -s \
                test/perf_test/test_perf_concurrent_redactions.py::test_concurrent_redactions_perf \
                --junitxml=junit/perf_test_results.xml
            displayName: 'Run perf tests (deployed env)'


          - task: PublishTestResults@2
            condition: succeededOrFailed()
            inputs:
              testResultsFiles: '**/perf_test_results.xml'
              mergeTestResults: true
