parameters:
- name: env
  type: string
  default: test
  values: [dev, test, prod]

- name: perfConcurrency
  type: number
  default: 5
- name: perfTotal
  type: number
  default: 5
- name: perfTimeoutSeconds
  type: number
  default: 7200
- name: perfPollSeconds
  type: number
  default: 2

pr: none
trigger: none

resources:
  repositories:
    - repository: templates
      type: github
      endpoint: Planning-Inspectorate
      name: Planning-Inspectorate/common-pipeline-templates
      ref: refs/tags/release/3.24.2

extends:
  template: stages/wrapper_ci.yml@templates
  parameters:
    validateName: Redaction Perf
    globalVariables:
      - template: pipelines/azure-pipelines-variables.yml@self

    validationJobs:
      - name: RunPerfTests
        steps:
          - checkout: self
            clean: true
          - checkout: templates

          # ---- Azure auth per env ----
          - ${{ if eq(parameters.env, 'dev') }}:
              - template: ../steps/azure_auth.yml@templates
                parameters:
                  subscriptionId: $(SUBSCRIPTION_ID_DEV)

          - ${{ if eq(parameters.env, 'test') }}:
              - template: ../steps/azure_auth.yml@templates
                parameters:
                  subscriptionId: $(SUBSCRIPTION_ID_TEST)

          - ${{ if eq(parameters.env, 'prod') }}:
              - template: ../steps/azure_auth.yml@templates
                parameters:
                  subscriptionId: $(SUBSCRIPTION_ID_PROD)

          - script: |
              set -e
              cd redaction-system
              python3 -m pip install -r redactor/requirements.txt
            displayName: Install requirements

          # ---- Env wiring per environment (clean + explicit) ----

          - ${{ if eq(parameters.env, 'dev') }}:
              - script: |
                  set -e
                  cd redaction-system/redactor
                  export PYTHONPATH="$(pwd)"

                  # Use ENV VARS, not $(...) command substitution
                  export E2E_FUNCTION_BASE_URL="${E2E_FUNCTION_BASE_URL_DEV}"
                  export E2E_CONTAINER_NAME="${E2E_CONTAINER_NAME_DEV}"
                  export E2E_STORAGE_ACCOUNT="pinsstredactiondevuks"
                  export E2E_RUN_ID="ado-perf-$(Build.BuildId)"

                  export PERF_CONCURRENCY="${{ parameters.perfConcurrency }}"
                  export PERF_TOTAL="${{ parameters.perfTotal }}"
                  export PERF_TIMEOUT_S="${{ parameters.perfTimeoutSeconds }}"
                  export PERF_POLL_S="${{ parameters.perfPollSeconds }}"

                  echo "E2E_FUNCTION_BASE_URL=${E2E_FUNCTION_BASE_URL}"
                  echo "E2E_CONTAINER_NAME=${E2E_CONTAINER_NAME}"

                  python3 -m pytest -q -s \
                    test/perf_test/test_perf_concurrent_redactions.py::test_concurrent_redactions_perf \
                    --junitxml=junit/perf_test_results.xml
                displayName: Run perf (dev)


          - ${{ if eq(parameters.env, 'test') }}:
              - script: |
                  set -e
                  cd redaction-system/redactor
                  export PYTHONPATH="$(pwd)"

                  export E2E_FUNCTION_BASE_URL="$(E2E_FUNCTION_BASE_URL_TEST)"
                  export E2E_CONTAINER_NAME="$(E2E_CONTAINER_NAME_TEST)"
                  export E2E_STORAGE_ACCOUNT="pinsstredactiontestuks"
                  export E2E_RUN_ID="ado-perf-$(Build.BuildId)"

                  export PERF_CONCURRENCY="${{ parameters.perfConcurrency }}"
                  export PERF_TOTAL="${{ parameters.perfTotal }}"
                  export PERF_TIMEOUT_S="${{ parameters.perfTimeoutSeconds }}"
                  export PERF_POLL_S="${{ parameters.perfPollSeconds }}"

                  python3 -m pytest -q -s \
                    test/perf_test/test_perf_concurrent_redactions.py::test_concurrent_redactions_perf \
                    --junitxml=junit/perf_test_results.xml
                displayName: Run perf (test)

          - ${{ if eq(parameters.env, 'prod') }}:
              - script: |
                  set -e
                  cd redaction-system/redactor
                  export PYTHONPATH="$(pwd)"

                  export E2E_FUNCTION_BASE_URL="$(E2E_FUNCTION_BASE_URL_PROD)"
                  export E2E_CONTAINER_NAME="$(E2E_CONTAINER_NAME_PROD)"
                  export E2E_STORAGE_ACCOUNT="pinsstredactionproduks"
                  export E2E_RUN_ID="ado-perf-$(Build.BuildId)"

                  export PERF_CONCURRENCY="${{ parameters.perfConcurrency }}"
                  export PERF_TOTAL="${{ parameters.perfTotal }}"
                  export PERF_TIMEOUT_S="${{ parameters.perfTimeoutSeconds }}"
                  export PERF_POLL_S="${{ parameters.perfPollSeconds }}"

                  python3 -m pytest -q -s \
                    test/perf_test/test_perf_concurrent_redactions.py::test_concurrent_redactions_perf \
                    --junitxml=junit/perf_test_results.xml
                displayName: Run perf (prod)

          - task: PublishTestResults@2
            condition: succeededOrFailed()
            inputs:
              testResultsFiles: '**/perf_test_results.xml'
              mergeTestResults: true
