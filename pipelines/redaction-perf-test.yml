parameters:
  - name: env
    default: test
    values:
      - dev
      - test
      - prod

  - name: perfConcurrency
    type: number
    default: 5
  - name: perfTotal
    type: number
    default: 5
  - name: perfTimeoutSeconds
    type: number
    default: 7200
  - name: perfPollSeconds
    type: number
    default: 2

pr: none
trigger: none

resources:
  repositories:
    - repository: templates
      type: github
      endpoint: Planning-Inspectorate
      name: Planning-Inspectorate/common-pipeline-templates
      ref: refs/tags/release/3.24.2

extends:
  template: stages/wrapper_ci.yml@templates
  parameters:
    validateName: Redaction Perf
    globalVariables:
      - template: pipelines/azure-pipelines-variables.yml@self

    validationJobs:
      - name: RunPerfTests
        steps:
          - checkout: self
            clean: true
          - checkout: templates

          - template: ../steps/azure_auth.yml@templates
            parameters:
              ${{ if eq(parameters.env, 'dev') }}:
                subscriptionId: $(SUBSCRIPTION_ID_DEV)
              ${{ if eq(parameters.env, 'test') }}:
                subscriptionId: $(SUBSCRIPTION_ID_TEST)
              ${{ if eq(parameters.env, 'prod') }}:
                subscriptionId: $(SUBSCRIPTION_ID_PROD)


          - script: |
              set -e
              cd redaction-system
              python3 -m pip install -r redactor/requirements.txt
            displayName: 'Install requirements'

          - script: |
              set -e
              cd redaction-system/redactor
              export PYTHONPATH="$(pwd)"

              echo "Running perf test against env=${{ parameters.env }}"
              echo "E2E_FUNCTION_BASE_URL=${E2E_FUNCTION_BASE_URL}"
              echo "E2E_STORAGE_ACCOUNT=${E2E_STORAGE_ACCOUNT}"
              echo "E2E_CONTAINER_NAME=${E2E_CONTAINER_NAME}"
              echo "PERF_CONCURRENCY=${PERF_CONCURRENCY} PERF_TOTAL=${PERF_TOTAL}"

              python3 -m pytest -q -s \
                test/perf_test/test_perf_concurrent_redactions.py::test_concurrent_redactions_perf \
                --junitxml=junit/perf_test_results.xml
            displayName: 'Run perf tests (deployed env)'
            env:
              # these come from pipelines/azure-pipelines-variables.yml@self
              E2E_FUNCTION_BASE_URL: ${{ variables[format('E2E_FUNCTION_BASE_URL_{0}', upper(parameters.env))] }}
              E2E_CONTAINER_NAME: ${{ variables[format('E2E_CONTAINER_NAME_{0}', upper(parameters.env))] }}

              # built from parameter
              E2E_STORAGE_ACCOUNT: pinsstredaction${{ parameters.env }}uks
              E2E_RUN_ID: ado-perf-$(Build.BuildId)

              # perf knobs
              PERF_CONCURRENCY: ${{ parameters.perfConcurrency }}
              PERF_TOTAL: ${{ parameters.perfTotal }}
              PERF_TIMEOUT_S: ${{ parameters.perfTimeoutSeconds }}
              PERF_POLL_S: ${{ parameters.perfPollSeconds }}

          - task: PublishTestResults@2
            displayName: 'Publish perf test results'
            condition: succeededOrFailed()
            inputs:
              testResultsFiles: '**/perf_test_results.xml'
              testRunTitle: 'Redaction perf report - $(Build.BuildId) - env=${{ parameters.env }}'
              mergeTestResults: true
              failTaskOnFailedTests: true

          - task: PublishBuildArtifacts@1
            displayName: 'Publish perf artefacts'
            condition: always()
            inputs:
              PathtoPublish: '$(Build.SourcesDirectory)/redaction-system/redactor/junit'
              ArtifactName: 'perf-junit'

          - task: PublishBuildArtifacts@1
            displayName: 'Publish run artefacts'
            condition: always()
            inputs:
              PathtoPublish: '$(Build.SourcesDirectory)/redaction-system'
              ArtifactName: 'perf-run-artifacts'
